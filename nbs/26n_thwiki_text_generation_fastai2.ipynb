{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "26n_thwiki_text_generation_fastai2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOaiEbCtkUzRjqSs7xELME9"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZt8uLBplcgs",
        "colab_type": "text"
      },
      "source": [
        "ใน ep นี้เราจะมาศึกษาอีก Concept นึงที่สำคัญของ [NLP](https://www.bualabs.com/archives/119/what-is-nlp-natural-language-processing-nlp-task-in-thai-nlp-ep-1/) คือ Language Model หรือ โมเดลของภาษา ซึ่งถ้าโมเดลของเรามีความสามารถที่จะเข้าใจภาษาโดยภาพรวมได้ดีระดับหนึ่งแล้ว ก็จะส่งผลให้โมเดลนั้นทำงานเฉพาะทาง เช่น [Classification](https://www.bualabs.com/archives/3087/sentiment-classification-deep-learning-imdb-movie-reviews-positive-negative-deep-neural-network-awd-lstm-ulmfit-nlp-ep-8/), [Sentiment Analysis](https://www.bualabs.com/archives/926/sentiment-analysis-imdb-movie-review-ulmfit-sentiment-analysis-ep-1/), Machine Translation, Question-Answer ได้ดีขึ้นไปด้วยในตัว"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRITFo9vgbpg",
        "colab_type": "text"
      },
      "source": [
        "# Language Model คืออะไร"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_yBgV6sgb0e",
        "colab_type": "text"
      },
      "source": [
        "Language Model คือ โมเดลว่าภาษานั้นเป็นอย่างไร ในทางสถิติคือ Probability Distribution ของลำดับของคำต่าง ๆ ว่าน่าจะเป็นคำอะไร เช่น ถ้าเราเข้าใจภาษาอังกฤษบ้าง เราก็จะพอเดาได้ว่าคำอะไรน่าจะอยู่ในช่องว่าง Somsak is a tall _____. และคำอะไรไม่น่าจะอยู่\n",
        "\n",
        "ในทางปฏิบัติ เราสามารถใช้วิธี Bag-of-word ดูทีละคำ (Uni-Gram) ทีละหลาย ๆ คำ [N-Gram](https://www.bualabs.com/archives/3060/what-is-n-gram-sentiment-classification-imdb-movie-review-naive-bayes-logistic-regression-nlp-ep-6/) ดูคำที่มาก่อน ดูคำที่มาทีหลัง หรือทั้งสองทิศทาง Bi-direction และใช้โมเดลคณิตศาสตร์ได้หลากหลาย \n",
        "\n",
        "แต่ในเคสนี้ เราจะใช้ Neural Network แบบ [Recurrent Neural Network - RNN](https://www.bualabs.com/archives/3103/what-is-rnn-recurrent-neural-network-what-is-gru-gated-recurrent-unit-teach-how-to-build-rnn-gru-with-python-nlp-ep-9/) แบบหนึ่ง เรียกว่า AWD_LSTM ที่ถูกเทรนด้วย Corpus ข้อความจาก Dumps Wikipedia ภาษาไทย โดยให้โมเดลเดาคำต่อไปเรื่อย ๆ\n",
        "\n",
        "เมื่อเราได้ Language Model จาก Wikipedia ภาษาไทย มาแล้ว เราสามารถใส่ข้อความภาษาไทยเริ่มต้นเข้าไปให้ Language Model เดาคำที่น่าจะเป็นคำต่อไป หรือก็คือ Generate Text สร้างข้อความใหม่ต่อ ๆ ไปได้ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dUbGObC56iZ",
        "colab_type": "text"
      },
      "source": [
        "# 0. Install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1N_zfQlldHA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "bce00d55-7f9d-4673-fb0f-2fdf99bc7fc2"
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed May 27 15:23:24 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08yoVC1wlcMx",
        "colab_type": "text"
      },
      "source": [
        "ติดตั้ง Library ที่จำเป็น"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1ZCrJ0plHlE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "5091bca2-b668-403c-e1ef-a0419f37c999"
      },
      "source": [
        "! pip install sklearn_crfsuite -q\n",
        "! pip install https://github.com/PyThaiNLP/pythainlp/archive/dev.zip -q\n",
        "! pip install fastai2 -q\n",
        "! pip install emoji -q"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 747kB 4.2MB/s \n",
            "\u001b[K     - 22.8MB 138kB/s\n",
            "\u001b[?25h  Building wheel for pythainlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 194kB 2.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 1.7MB/s \n",
            "\u001b[?25h  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "in8cLMpLlVbQ",
        "colab_type": "text"
      },
      "source": [
        "# 1. Import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k55Aq8aCqqjL",
        "colab_type": "text"
      },
      "source": [
        "Import ในที่นี้เราจะใช้ [PyThaiNLP](https://www.bualabs.com/archives/3234/what-is-pythainlp-tutorial-teach-basic-how-to-use-pythainlp-library-nlp-in-python-pythainlp-ep-1/) และ [fastai2](https://www.bualabs.com/archives/4102/tutorial-fastai2-oxford-pets-dog-cat-37-class-machine-learning-deep-neural-networks-image-classification-ep-7/) text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZxgbbElloXa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "0a0d5ceb-9a44-4260-ff29-69cb22cd41eb"
      },
      "source": [
        "from fastai2.basics import *\n",
        "from fastai2.text.all import *\n",
        "\n",
        "from pythainlp.ulmfit import *\n",
        "from pythainlp.tokenize import THAI2FIT_TOKENIZER"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corpus: wiki_lm_lstm\n",
            "- Downloading: wiki_lm_lstm 0.32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1050919089/1050919089 [05:17<00:00, 3307292.88it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Corpus: wiki_itos_lstm\n",
            "- Downloading: wiki_itos_lstm 0.32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1530484/1530484 [00:07<00:00, 194956.20it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrWeoYeAloa_",
        "colab_type": "text"
      },
      "source": [
        "# 2. Dummy Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2hW7JBnrC_B",
        "colab_type": "text"
      },
      "source": [
        "สั่ง Download Dummy Dataset ขนาดเล็ก มาสำหรับใช้สร้าง Model แต่เราจะไม่ได้ใช้ Dataset ส่วนนี้มาทำงานอะไร เพราะเป็นภาษาอังกฤษ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVD_RPhDlofd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "05475488-ce68-4fae-b6ad-e50b7f62db4c"
      },
      "source": [
        "imdb = untar_data(URLs.IMDB_SAMPLE)\n",
        "dummy_df = pd.read_csv(imdb/'texts.csv')\n",
        "\n",
        "# dummy_df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1tx5q4-mRES",
        "colab_type": "text"
      },
      "source": [
        "# 3. Data pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZmzdaG66SQO",
        "colab_type": "text"
      },
      "source": [
        "เราจะกำหนด [Tokenizer](https://www.bualabs.com/archives/3740/python-word-tokenize-pythainlp-example-algorithm-deepcut-newmm-longest-python-pythainlp-ep-2/) ตัวตัดคำภาษาไทย สำหรับใช้ใน Data pipeline ของ fastai2 ด้วยตัวตัดคำจาก [pythainlp](https://www.bualabs.com/archives/3234/what-is-pythainlp-tutorial-teach-basic-how-to-use-pythainlp-library-nlp-in-python-pythainlp-ep-1/) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoPYM08NrBsw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class XThaiTokenizer():\n",
        "    def __init__(self, lang: str = \"th\", split_char=' ', **kwargs): \n",
        "        self.split_char=split_char\n",
        "        self.lang = lang\n",
        "\n",
        "    def __call__(self, items): return (THAI2FIT_TOKENIZER.word_tokenize(t) for t in items)\n",
        "\n",
        "    def add_special_cases(self, toks):\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bN5KV-Xe6MHZ",
        "colab_type": "text"
      },
      "source": [
        "โหลด Vocab Dictionary ของ Wikipedia ภาษาไทย เตรียมเอาไว้ใส่ใน Data Pipeline เนื่องจากเราจะใช้ Pre-train Model เราจึงต้องใช้ Vocab เดียวกันกับโมเดลนั้น ๆ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q34dlVGelojB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "ae5e207d-f9da-4ba4-8adc-3b70a00ebca5"
      },
      "source": [
        "thwiki_vocab = pickle.load(open(THWIKI_LSTM['itos_fname'],'rb'))\n",
        "\n",
        "len(thwiki_vocab), thwiki_vocab[:20]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60005,\n",
              " ['xxunk',\n",
              "  'xxpad',\n",
              "  'xxbos',\n",
              "  'xxfld',\n",
              "  'xxmaj',\n",
              "  'xxup',\n",
              "  'xxrep',\n",
              "  'xxwrep',\n",
              "  ' ',\n",
              "  '\\n',\n",
              "  'ใน',\n",
              "  'ที่',\n",
              "  'และ',\n",
              "  'ของ',\n",
              "  'เป็น',\n",
              "  'มี',\n",
              "  'ได้',\n",
              "  'การ',\n",
              "  '\"',\n",
              "  '('])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ca_jPyGcrBHK",
        "colab_type": "text"
      },
      "source": [
        "สร้าง Data Pipeline ด้วย fastai2 DataBlock API โดยใส่ tokenizer และ vocab จากด้านบน"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abBYR7VzmoVk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imdb_lm = DataBlock(blocks=TextBlock.from_df('text', is_lm=True, tok_func=XThaiTokenizer, vocab=thwiki_vocab, sep=''),\n",
        "                    get_x=ColReader('text'),    \n",
        "                    splitter=ColSplitter())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12lJZAKWmoda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imdb_lm.summary(dummy_df, bs=64, seq_len=72)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "to2CB9lXsaBy",
        "colab_type": "text"
      },
      "source": [
        "สร้าง DataLoader จาก DataBlock"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzcTlNpHmohi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "26b40427-85e0-4204-be43-8e825cf93848"
      },
      "source": [
        "dls = imdb_lm.dataloaders(dummy_df, bs=64, seq_len=72)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AvP1oxysdOb",
        "colab_type": "text"
      },
      "source": [
        "เช็คขนาด Vocab ของ DataLoader อีกที จะเห็นว่าเท่ากันกับ Vocab จาก Wikipedia ภาษาไทย ที่เราโหลดมา"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNR5EupBt00F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1cf770ba-4167-4ca4-c840-f71118827914"
      },
      "source": [
        "len(dls.vocab)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60005"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cq0XmQGu_Wj",
        "colab_type": "text"
      },
      "source": [
        "เราสามารถเรียก show_batch ดูข้อมูลได้ แต่เนื่องจาก Dataset ภาษาอังกฤษ แต่ตัดคำไทย Vocab Dictionary เป็นภาษาไทย อาจจะมีคำภาษาอังกฤษน้อย คำที่ไม่อยู่ใน Vocab ก็จะกลายเป็น UNK ไปหมด"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iEVw9TlqYOF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dls.show_batch(max_n=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoNMu2-Bqabk",
        "colab_type": "text"
      },
      "source": [
        "# 4. Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXaBQw2Bs5Qd",
        "colab_type": "text"
      },
      "source": [
        "สร้าง Language Model Learning ด้วยโมเดล AWD_LSTM โดยกำหนด Hyperparameter ให้ตรงตาม Pre-trained คือ emb_sz=400, n_hid=1550, n_layers=4, pad_token=1 แต่ไม่ต้องโหลด Weight มาด้วย pretrained=False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcEuzdoKM1so",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# language_model_learner??\n",
        "# AWD_LSTM??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7j6MOXRYuurx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = dict(emb_sz=400, n_hid=1550, n_layers=4, pad_token=1, tie_weights=True, out_bias=True,\n",
        "             output_p=0.25, hidden_p=0.1, input_p=0.2, embed_p=0.02, weight_p=0.15)\n",
        "\n",
        "trn_args = dict(drop_mult=0.9, clip=0.12, alpha=2, beta=1)\n",
        "\n",
        "learn = language_model_learner(dls, AWD_LSTM, config=config, pretrained=False, **trn_args)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lABplVj9tYiJ",
        "colab_type": "text"
      },
      "source": [
        "ดูสถิติโมเดล"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BEGDJuL4d5o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "ccd5b3c6-8780-4755-9955-51d6b58e03a8"
      },
      "source": [
        "learn.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequentialRNN (Input shape: ['64 x 72'])\n",
              "================================================================\n",
              "Layer (type)         Output Shape         Param #    Trainable \n",
              "================================================================\n",
              "RNNDropout           64 x 72 x 400        0          False     \n",
              "________________________________________________________________\n",
              "RNNDropout           64 x 72 x 1550       0          False     \n",
              "________________________________________________________________\n",
              "RNNDropout           64 x 72 x 1550       0          False     \n",
              "________________________________________________________________\n",
              "RNNDropout           64 x 72 x 1550       0          False     \n",
              "________________________________________________________________\n",
              "Linear               64 x 72 x 60005      24,062,005 True      \n",
              "________________________________________________________________\n",
              "RNNDropout           64 x 72 x 400        0          False     \n",
              "________________________________________________________________\n",
              "\n",
              "Total params: 24,062,005\n",
              "Total trainable params: 24,062,005\n",
              "Total non-trainable params: 0\n",
              "\n",
              "Optimizer used: <function Adam at 0x7f79745136a8>\n",
              "Loss function: FlattenedLoss of CrossEntropyLoss()\n",
              "\n",
              "Callbacks:\n",
              "  - TrainEvalCallback\n",
              "  - Recorder\n",
              "  - ProgressCallback\n",
              "  - ModelReseter\n",
              "  - RNNRegularizer"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKH2jRc46b3t",
        "colab_type": "text"
      },
      "source": [
        "# 5. Load Pretrained Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJ53Dna8tdTE",
        "colab_type": "text"
      },
      "source": [
        "โหลด Weight และ Vocab ของ Pre-trained Model จากใน pythainlp.ulmfit เราจะได้โมเดลที่เข้าใจ ภาษาไทยใน Wikipedia มาเรียบร้อย"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aX095WmOtomO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# THWIKI_LSTM??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OceSXzr3zFfa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "622a6fcd-ead5-4ee8-f7c9-94ad6502bc9e"
      },
      "source": [
        "learn.load_pretrained(THWIKI_LSTM['wgts_fname'], THWIKI_LSTM['itos_fname'])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<fastai2.text.learner.LMLearner at 0x7f790e8e6dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gwmnf8DB54m5",
        "colab_type": "text"
      },
      "source": [
        "# 6. Generate Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAzL_M2buCyc",
        "colab_type": "text"
      },
      "source": [
        "เมื่อเราได้โมเดลที่โหลดทุกอย่างเรียบร้อย พร้อมทำงาน เราจะมาลอง Generate Text กัน"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKIiWgIU4dNf",
        "colab_type": "text"
      },
      "source": [
        "## ตัวอย่าง 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eF2vfPZ5uuvQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "ebc9d2e3-0f17-4208-8ff7-a827b47c0b79"
      },
      "source": [
        "print(learn.predict('ประวัติศาสตร์ไทย เริ่มต้นขึ้นเมื่อ', 200, temperature=0.8))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            " ประวัติศาสตร์ไทย เริ่มต้นขึ้นเมื่อพุทธศตวรรษที่ 24 เมื่อสมัยกรุงศรีอยุธยาเป็นราชธานี โดยมีพระเจ้าปราสาททองเป็นครองราชย์ ส่วนสมเด็จพระเจ้ากรุงธนบุรีเป็นกษัตริย์แห่งกรุงศรีอยุธยา คือ พระเจ้าอู่ทอง พระราชโอรสของสมเด็จพระนารายณ์มหาราช \n",
            " \n",
            "  สมัยอยุธยา. \n",
            " สมัยกรุงศรีอยุธยา หลังคริสต์ศตวรรษที่ 17 เมืองอยุธยาได้ถูกทำลายเสียหมดแล้ว โดยกรุงศรีอยุธยาถูกยกให้เป็นเมืองประเทศราชของกรุงศรีอยุธยาเมืองลพบุรี มีการสร้างกำแพงเมือง ตลอดจนป้อมปราการ จนกระทั่งถึงสมัยกรุงรัตนโกสินทร์ เมื่อ พ.ศ. 1956 สมัยที่พระเจ้ากรุงธนบุรีทรงสถาปนากรุงศรีอยุธยาขึ้น พระเจ้าติโลกราชทรงพยายามทำทั้ง 2 ด้านให้ทันสมัย พระองค์ทรงออกแบบเมืองไทยให้มีขนาดใหญ่กว่าเดิม มีตัวอาคารกว้าง 15 เมตร ยาว 75 เมตร และมีการสร้างซุ้มประตูล้อมรอบ ได้มีการสร้างบันไดเรือ (phantom หินย้อย) สำหรับสร้างสะพาน \n",
            " \n",
            " ต่อมาในรัชสมัยของสมเด็จพระรามาธิบดีที่ 1 แห่งสยาม พระองค์ทรงถูกยกทัพเข้ามา\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1Uv7pVK5yde",
        "colab_type": "text"
      },
      "source": [
        "## ตัวอย่าง 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lW7DztZcuV8m",
        "colab_type": "text"
      },
      "source": [
        "Generate 5 ครั้ง เพื่อเปรียบเทียบ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pG7j04IwvCsf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "5535002b-d922-4533-87ee-b983bdc893b1"
      },
      "source": [
        "TEXT = \"ประวัติศาสตร์ไทย เริ่มต้นขึ้นเมื่อ\"\n",
        "N_WORDS = 50\n",
        "N_SENTENCES = 5\n",
        "\n",
        "preds = [learn.predict(TEXT, N_WORDS, temperature=0.6) \n",
        "         for _ in range(N_SENTENCES)]\n",
        "\n",
        "preds"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' ประวัติศาสตร์ไทย เริ่มต้นขึ้นเมื่อ พ.ศ. 2511 โดย พระยาพหลพลพยุหเสนา (พจน์ พหลโยธิน) ซึ่งเป็นผู้ที่ได้เป็นผู้นำในการสร้างทางรถไฟสายใต้ และการสร้างทางรถไฟสายใต้ (สาย สระบุรี-บางขุนเทียน) \\n',\n",
              " ' ประวัติศาสตร์ไทย เริ่มต้นขึ้นเมื่อ พ.ศ. 2534 ระหว่าง ไทยกับฝรั่งเศส (พ.ศ. 2533-2532) โดยการส่งกำลังทหารไปโจมตีญี่ปุ่น \\n \\n การยึดครองประเทศไทย. \\n หลังจากญี่ปุ่นพ่ายแพ้สงคราม ญี่ปุ่นก็ออกปฏิบัติการในด้าน',\n",
              " ' ประวัติศาสตร์ไทย เริ่มต้นขึ้นเมื่อ พ.ศ. 2446 โดย จอมพล ป.พิบูลสงคราม และ จอมพลสฤษดิ์ ธนะรัชต์ ได้เดินทางมายังกรุงเทพมหานคร เพื่อร่วมรบในสงครามอินโดจีนครั้งที่หนึ่ง ซึ่งในช่วงนั้น ทหารญี่ปุ่นได้ทำสงคราม กับกองทัพญี่ปุ่น และ กองทัพญี่ปุ่น',\n",
              " ' ประวัติศาสตร์ไทย เริ่มต้นขึ้นเมื่อ พ.ศ. 2477 โดยจอมพล ป. เป็นนายกรัฐมนตรี และได้มีการจัดตั้ง \"สภาพัฒนาการเศรษฐกิจแห่งชาติ\" ขึ้น โดยองค์กรที่มีหน้าที่รับผิดชอบในการจัดตั้ง \"สภาพัฒนาการเศรษฐกิจแห่งชาติ\" ขึ้น โดยมี ',\n",
              " ' ประวัติศาสตร์ไทย เริ่มต้นขึ้นเมื่อ พ.ศ. 2473 โดย พระยาบรมราชภักดี (หม่อมหลวงเฟื้อ พึ่งบุญ) และ พระยาทรงสุรเดช (บุญรอด โกมารกุล ณ นคร) ได้ร่วมกันสร้าง \"อนุสาวรีย์พระบาทสมเด็จ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZxB8w6S50uk",
        "colab_type": "text"
      },
      "source": [
        "## ตัวอย่าง 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyktSuBDueke",
        "colab_type": "text"
      },
      "source": [
        "เราสามารถปรับ temperature เพื่อให้ได้คำที่หลากหลายยิ่งขึ้น"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1p2cmVIrv0X0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "4015446a-dab1-48b1-bfc5-40e32de67e35"
      },
      "source": [
        "TEXT = \"ประวัติศาสตร์ไทย เริ่มต้นขึ้นเมื่อ\"\n",
        "N_WORDS = 50\n",
        "N_SENTENCES = 5\n",
        "\n",
        "preds = [learn.predict(TEXT, N_WORDS, temperature=0.9) \n",
        "         for _ in range(N_SENTENCES)]\n",
        "\n",
        "preds"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' ประวัติศาสตร์ไทย เริ่มต้นขึ้นเมื่อกรุงเทพฯ ได้ส่งเรือลงไปสำรวจป่า และเยี่ยมชมเกาะโบราณแห่งหนึ่งที่ยังมีนกที่เพิ่งดั้งเดิมมาร่วม 10 ตัว จึงคิดเลือกว่าจะตั้งชื่อประเทศว่า \"ประเทศไทย\" ครั้งหนึ่ง old s.s',\n",
              " ' ประวัติศาสตร์ไทย เริ่มต้นขึ้นเมื่อ \\n \\n พ.ศ. 2515  ทหารเขมรแดงได้เคลื่อนขบวนไปยังบ้านหลวงพระบาง และได้รู้จักข้าราชการ และวีรบุรุษในรัฐบาลไทย ที่จับมาแต่ต้น โดยไม่สนใจความวุ่นวายใดๆ แต่ไม่ยอมจำนนขึ้นไปยังประเทศ',\n",
              " ' ประวัติศาสตร์ไทย เริ่มต้นขึ้นเมื่อปี 2531 นับตั้งแต่ พล.ต.ท.หริส\" เทพหัสดิน ณ อยุธยา ผู้บัญชาการตำรวจแห่งชาติ เป็นต้นมา และ ดร. รื่น สุวรรณนะ หัวหน้าคณะในพันธ์ไทยรัฐบาลได้จัดตั้ง \"กองทุนร่วมกู้วัฒนธรรมไทย\" ที่',\n",
              " ' ประวัติศาสตร์ไทย เริ่มต้นขึ้นเมื่อ พ.ศ. 2458 เมื่อ ปรีดี พนมยงค์ ได้รับเชิญจากหนังสือพิมพ์สยามรัฐให้เดินทางไปสำรวจสถานที่ ณ เมืองบัควิลล์ รัฐควิเบก สหรัฐอเมริกา โดยได้ส่งตัวอย่าง มะนิลา ',\n",
              " ' ประวัติศาสตร์ไทย เริ่มต้นขึ้นเมื่อ เขามิชชันนารีdi อภัยวงศ์ ได้พัฒนาพระพุทธศาสนาเป็นศาสนสถานที่สำคัญและมีจำนวนประชากรมากที่สุดในโลก เมื่อ พ.ศ. 2528 การสร้างวัดไทยต่อจากพุทธศาสนา ในทางการเมือง เป็นส่วนหนึ่งของการเผยแพร่พระพุทธศาสนาในประเทศไทย ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZm4dZMG3deb",
        "colab_type": "text"
      },
      "source": [
        "# Credit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6TpkMsd3dio",
        "colab_type": "text"
      },
      "source": [
        "* https://www.thainlp.org/pythainlp/tutorials/notebooks/text_generation.html\n",
        "* https://thainlp.org/pythainlp/docs/2.0/_modules/pythainlp/ulmfit.html\n",
        "* http://dev.fast.ai/tutorial.wikitext\n",
        "* https://arxiv.org/abs/1708.02182\n",
        "* https://dumps.wikimedia.org/thwiki/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IILaY6O93evz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}